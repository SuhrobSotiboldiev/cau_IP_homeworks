# -*- coding: utf-8 -*-
"""IP Assignment#3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L6TzvdE83SKNEn5NRBNgQoq5b5_zGtnC
"""

import numpy as np
import cv2
from google.colab.patches import cv2_imshow

# This all for Filters

class Filters:
    def __init__(self, image, window_size, Q, d):
        self.image= image
        self.window_size = window_size
        self.Q = Q
        self.d = d

    def arithmetic_mean(self):
        kernel = np.ones((self.window_size, self.window_size), np.float32) / (self.window_size * self.window_size)
        filtered_image = cv2.filter2D(src=self.image, ddepth=-1, kernel=kernel)
        print(self.window_size)

        return filtered_image

    def geometric_mean(self):
        output_image = np.zeros_like(self.image, dtype=np.float64)

        padded_image = cv2.copyMakeBorder(self.image, self.window_size // 2, self.window_size // 2, self.window_size // 2, self.window_size // 2, cv2.BORDER_REFLECT)

        for i in range(self.image.shape[0]):
            for j in range(self.image.shape[1]):
                crop = padded_image[i:i + self.window_size, j:j + self.window_size]
                output_image[i, j] = np.prod(crop) ** (1.0 / (self.window_size * self.window_size))

        return np.uint8(output_image)

    def median_filter(self):

        height, width = self.image.shape
        filtered_image = np.zeros_like(self.image, dtype=np.uint8)

        padded_image = cv2.copyMakeBorder(self.image, self.window_size // 2, self.window_size // 2, self.window_size // 2, self.window_size // 2, cv2.BORDER_REFLECT)

        for i in range(height):
            for j in range(width):

                crop = padded_image[i:i + self.window_size, j:j + self.window_size]

                median_value = np.median(crop)

                filtered_image[i, j] = int(median_value)

        return filtered_image

    def max_filter(self):

        height, width = self.image.shape
        max_intensity = 255 if np.max(self.image) > 1 else 1
        max_pixels = (self.image == max_intensity).sum()
        total_pixels = self.image.size

        # if (max_pixels / total_pixels) > 0.03:
        #     raise ValueError("More than 3% of the pixels have intensity 255 (or 1 in normalized image)")

        filtered_image = np.zeros_like(self.image, dtype=np.uint8)

        for i in range(height):
            for j in range(width):

                window = self.image[i:i+self.window_size, j:j+self.window_size]

                max_value = np.max(window)

                filtered_image[i, j] = max_value

        return filtered_image

    def min_filter(self):
        height, width = self.image.shape
        zero_pixels = (self.image == 0).sum()
        total_pixels = self.image.size

        # if (zero_pixels / total_pixels) > 0.03:
        #     raise ValueError("More than 3% of the pixels have intensity 0")

        filtered_image = np.zeros_like(self.image, dtype=np.uint8)

        for i in range(height):
            for j in range(width):

                window = self.image[i:i+self.window_size, j:j+self.window_size]

                min_value = np.min(window)

                filtered_image[i, j] = min_value

        return filtered_image

    def mid_point_filter(self):
        border = self.window_size // 2
        result = np.zeros_like(self.image)

        for i in range(border, self.image.shape[0] - border):
            for j in range(border, self.image.shape[1] - border):
                window = self.image[i - border : i + border + 1, j - border : j + border + 1]
                min_val = np.min(window)
                max_val = np.max(window)
                mid_point = (min_val + max_val) / 2
                result[i, j] = mid_point

        return result

    def harmonic_mean(self):

        border = self.window_size // 2
        result = np.zeros_like(self.image, dtype=np.float64)

        for i in range(border, self.image.shape[0] - border):
            for j in range(border, self.image.shape[1] - border):
                window = self.image[i - border : i + border + 1, j - border : j + border + 1]
                inverse_mean = np.mean(1.0 / (window + 1e-6))
                result[i, j] = 1.0 / inverse_mean

        result = np.uint8(result)

        return result

    def contra_harmonic_mean(self):
        noisy_pixels = (self.image == 0).sum()
        total_pixels = self.image.size

        if self.Q < 0 and (noisy_pixels / total_pixels) > 0.03:
            raise ValueError("Negative Q doesn't support pepper noise")

        if self.Q > 0 and (noisy_pixels / total_pixels) < 0.03:
            raise ValueError("Positive Q doesn't support salt noise")

        height, width = self.image.shape
        filtered_image = np.zeros_like(self.image, dtype=np.uint8)

        for i in range(height):
            for j in range(width):

                window = self.image[i:i+self.window_size, j:j+self.window_size]

                numerator = np.sum(np.power(window, self.Q+1))
                denominator = np.sum(np.power(window, self.Q))

                if denominator == 0:
                    filtered_image[i, j] = 0
                else:
                    filtered_image[i, j] = int(numerator / denominator)

        return filtered_image

    def alpha_trimmed_mean(self):
        if self.d >= (self.image.shape[0] * self.image.shape[1] - 1):
            raise ValueError("Invalid value of d. It should be less than (image_height * image_width - 1)")

        padded_image = np.pad(self.image, (self.window_size//2, self.window_size//2), mode='constant')  # Padding the noisy image

        result = np.zeros_like(self.image)

        for i in range(self.window_size//2, self.image.shape[0] + self.window_size//2):
            for j in range(self.window_size//2, self.image.shape[1] + self.window_size//2):
                neighbors = padded_image[i - self.window_size//2:i + self.window_size//2 + 1, j - self.window_size//2:j + self.window_size//2 + 1]
                sorted_neighbors = np.sort(neighbors, axis=None)
                valid_neighbors = sorted_neighbors[self.d:-self.d] if self.d > 0 else sorted_neighbors
                result[i - self.window_size//2, j - self.window_size//2] = np.mean(valid_neighbors)

        return result

    def call_filters(self, flag: int, window_size: int, noise_image, d):

        """
        call_filters :
        :param: int flag number
        :param: int window_size
        :param: image noise_image
        """

        filtered = None
        self.window_size = window_size
        self.image = noise_image
        self.d = d
        # callers = {
        #     1: self.arithmetic_mean,
        #     2: self.geometric_mean,

        # }
        # return callers[flag]() if flag in callers else None


        if(flag == 1):
            filtered = self.arithmetic_mean()

        elif(flag == 2):
            filtered = self.geometric_mean()

        elif(flag == 3):
            filtered = self.harmonic_mean()

        elif(flag == 4):
            filtered = self.contra_harmonic_mean()

        elif(flag == 5):
            filtered = self.alpha_trimmed_mean()

        elif(flag == 6):
            filtered = self.min_filter()

        elif(flag == 7):
            filtered = self.max_filter()

        elif(flag == 8):
            filtered = self.median_filter()

        elif(flag == 9):
            filtered = self.mid_point_filter()

        return filtered

def printi(image):
  cv2_imshow(image)

# image2 = cv2.imread('/content/image2.tif')
# image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
# filters = Filters(None, None, None, None)

# task = filters.call_filters(9, 3, image2)
# printi(task)

# This is all for Segmantations

class Segmentations:
    def __init__(self, image, flag_filter, flag_smooth, threshold):
        self.image= image
        self.flag_filter = flag_filter
        self.flag_smooth = flag_smooth
        self.threshold = threshold

    def image_segmentation(img, threshold):
        segmented_img = np.zeros_like(img)
        segmented_img[img > threshold] = 255
        return segmented_img

    def prewitt_operator(self):
        kernel_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])
        kernel_y = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])

        img_x = cv2.filter2D(self.image, -1, kernel_x)
        img_y = cv2.filter2D(self.image, -1, kernel_y)

        gradient_magnitude = np.sqrt(img_x**2 + img_y**2)
        # Normalize gradient magnitude to [0, 255]
        gradient_magnitude = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)
        segmented_image = image_segmentation(gradient_magnitude, self.threshold)
        return segmented_image

    def sobel_operator(self):
        kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
        kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])

        img_x = cv2.filter2D(self.image, -1, kernel_x)
        img_y = cv2.filter2D(self.image, -1, kernel_y)

        gradient_magnitude = np.sqrt(img_x ** 2 + img_y ** 2)
        gradient_magnitude = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)
        segmented_image = image_segmentation(gradient_magnitude, self.threshold)
        return segmented_image

    def robert(self):
        kernel_x = np.array([[1, 0], [0, -1]])
        kernel_y = np.array([[0, 1], [-1, 0]])

        gradient_x = cv2.filter2D(self.image, -1, kernel_x)
        gradient_y = cv2.filter2D(self.image, -1, kernel_y)

        gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)
        gradient_magnitude = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)
        segmented_image = np.zeros_like(self.image)
        segmented_image[gradient_magnitude > self.threshold] = 255
        return segmented_image

    def Robert_45(self):
        kernel_x = np.array([[1, 0], [0, -1]])
        kernel_y = np.array([[0, 1], [-1, 0]])

        img_x = cv2.filter2D(self.image, -1, kernel_x)
        img_y = cv2.filter2D(self.image, -1, kernel_y)

        gradient_magnitude = np.sqrt(img_x**2 + img_y**2)
        gradient_magnitude = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)
        segmented_image = image_segmentation(gradient_magnitude, self.threshold)
        return segmented_image

    def prewitt_45(self):
        kernel_x = np.array([[0, 1, 1], [-1, 0, 1], [-1, -1, 0]])
        kernel_y = np.array([[1, 1, 0], [1, 0, -1], [0, -1, -1]])

        img_x = cv2.filter2D(self.image, -1, kernel_x)
        img_y = cv2.filter2D(self.image, -1, kernel_y)

        gradient_magnitude = np.sqrt(img_x**2 + img_y**2)
        gradient_magnitude = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)
        segmented_image = image_segmentation(gradient_magnitude, self.threshold)
        return segmented_image

    def sobel_45(self):
        kernel_x = np.array([[0, 1, 2], [-1, 0, 1], [-2, -1, 0]])
        kernel_y = np.array([[2, 1, 0], [1, 0, -1], [0, -1, -2]])

        img_x = cv2.filter2D(self.image, -1, kernel_x)
        img_y = cv2.filter2D(self.image, -1, kernel_y)

        gradient_magnitude = np.sqrt(img_x**2 + img_y**2)
        gradient_magnitude = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)
        segmented_image = image_segmentation(gradient_magnitude, self.threshold)
        return segmented_image

    def eight_compass_filter(self):
        compass_kernels = [
                np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]), # North
                np.array([[-1, -1, -1], [1, 1, 1], [1, 1, 1]]),      # North-East
                np.array([[-1, -1, 2], [-1, 2, -1], [2, -1, -1]]),   # East
                np.array([[1, 1, 1], [-1, -1, -1], [-1, -1, -1]]),   # South-East
                np.array([[2, -1, -1], [-1, 2, -1], [-1, -1, 2]]),   # South
                np.array([[-1, -1, -1], [-1, -1, -1], [1, 1, 1]]),   # South-West
                np.array([[-1, 2, -1], [2, -1, 2], [-1, 2, -1]]),    # West
                np.array([[1, 1, 1], [1, 1, 1], [-1, -1, -1]])       # North-West
            ]
        gradient_magnitude = np.zeros_like(self.image)
        for kernel in compass_kernels:
            response = cv2.filter2D(self.image, -1, kernel)
            gradient_magnitude = np.maximum(gradient_magnitude, response)

        gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255)

        # Apply threshold
        segmented_image = image_segmentation(gradient_magnitude, self.threshold)

        return segmented_image

    def kirsch_opperator_apply(self):

        kernels = [
            np.array([[5, 5, 5],
                    [-3, 0, -3],
                    [-3, -3, -3]]),

            np.array([[-3, 5, 5],
                    [-3, 0, 5],
                    [-3, -3, -3]]),

            np.array([[-3, -3, 5],
                    [-3, 0, 5],
                    [-3, -3, 5]]),

            np.array([[-3, -3, -3],
                    [-3, 0, 5],
                    [-3, 5, 5]]),

            np.array([[-3, -3, -3],
                    [-3, 0, -3],
                    [5, 5, 5]]),

            np.array([[-3, -3, -3],
                    [5, 0, -3],
                    [5, 5, -3]]),

            np.array([[5, -3, -3],
                    [5, 0, -3],
                    [5, -3, -3]]),

            np.array([[5, 5, -3],
                    [5, 0, -3],
                    [-3, -3, -3]])
        ]

        gradient_magnitude = np.zeros_like(self.image)
        for kernel in kernels:
            response = cv2.filter2D(self.image, -1, kernel)
            gradient_magnitude = np.maximum(gradient_magnitude, response)

        gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255)

        # Apply threshold
        segmented_image = image_segmentation(gradient_magnitude, self.threshold)

        return segmented_image

    def call_segmentation(self, flag_filter, flag_smooth, image_gray, threshold = 50):


        filtered = None
        self.flag_filter = flag_filter
        self.image = image_gray
        self.threshold = threshold

        if (flag_smooth == 1):
            ksize = (3, 3)
            sigma = 0
            image_gray = cv2.GaussianBlur(image_gray, ksize, sigma)


        if(flag_filter == 1):
            filtered = self.prewitt_operator()

        elif(flag_filter == 2):
            filtered = self.sobel_operator()

        elif(flag_filter == 3):
            filtered = self.Robert_45()

        elif(flag_filter == 4):
            filtered = self.prewitt_45()

        elif(flag_filter == 5):
            filtered = self.sobel_45()

        elif(flag_filter == 6):
            filtered = self.eight_compass_filter()

        elif(flag_filter == 7):
             filtered = self.kirsch_opperator_apply()

        return filtered

# image = cv2.imread("Lena.jpg")
# image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
# segmentations = Segmentations(None, None, None, None)

# task = segmentations.call_segmentation(4, 1, image, 100)
# printi(task)

"""Peak signal to noise ratio (PSNR) and Structure Similarity Index Measure(SSIM) are two common approaches to measure the performance of any filter"""

image1 = cv2.imread('/content/drive/MyDrive/Noisy images/Gaussian/G50C.png')
image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
image2 = cv2.imread('/content/drive/MyDrive/Noisy images/Gaussian & SNP/GSNP50C.png')
image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
filters = Filters(None, None, None, None)

from skimage.metrics import peak_signal_noise_ratio, structural_similarity

for i in range(1, 4):
    task1 = filters.call_filters(i, 11, image1)
    task2 = filters.call_filters(i, 11, image2)

    psnr1 = peak_signal_noise_ratio(image1, task1)
    ss1 = structural_similarity(image1, task1)

    psnr2 = peak_signal_noise_ratio(image2, task2)
    ss2 = structural_similarity(image2, task2)

    print(f"flag{i}, size:3, image1", psnr1, ss1)
    print(f"flag{i}, size:3, image2", psnr2, ss2)

for i in range(5, 8):
    task1 = filters.call_filters(5, 9, image1, 2*i)
    task2 = filters.call_filters(5, 9, image2, 2*i)

    psnr1 = peak_signal_noise_ratio(image1, task1)
    ss1 = structural_similarity(image1, task1)

    psnr2 = peak_signal_noise_ratio(image2, task2)
    ss2 = structural_similarity(image2, task2)

    print(f" d = {2*i}, size:3, image1", psnr1, ss1)
    print(f" d = {2*i}, size:3, image2", psnr2, ss2)